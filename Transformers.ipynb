{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6e59011d",
   "metadata": {},
   "source": [
    "[Chat](https://chat.cborg.lbl.gov/c/b21a4f92-e4b2-401d-9f41-7293644a27ff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a51b840d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5a35eed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import random\n",
    "import math\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18878ef4",
   "metadata": {},
   "source": [
    "## Positional Encoding\n",
    "\n",
    "Positional encoding itself does not go directly into the \"attention\" mechanism by itself — it is added to the token embeddings before the attention layers, so the attention mechanism can make use of positional information."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6c241fa",
   "metadata": {},
   "source": [
    "### How Transformers Process Input\n",
    "In a transformer encoder, the first few steps look like this:\n",
    "\n",
    "\n",
    "### Tokens → Embeddings\n",
    "Each word (or subword) in your sequence is mapped to a dense vector:\n",
    "$$\\text{token\\_embedding} \\in \\mathbb{R}^{d_{\\text{model}}}$$\n",
    "This captures semantic meaning but has no position info.\n",
    "\n",
    "\n",
    "### Add Positional Encoding\n",
    "We add the positional encoding vector to each token embedding:\n",
    "$$\\text{input\\_to\\_transformer} = \\text{token\\_embedding} + \\text{positional\\_encoding}$$\n",
    "Now each vector contains both word meaning and position.\n",
    "\n",
    "\n",
    "### Feed Into Self-Attention\n",
    "The resulting vectors (with position info baked in) are used to compute Queries (Q), Keys (K), and Values (V) for the attention mechanism:\n",
    "$$Q = XW_Q, \\quad K = XW_K, \\quad V = XW_V$$\n",
    "where $X$ is the sum of token embeddings and positional encodings.\n",
    "\n",
    "\n",
    "### Attention Calculation\n",
    "The self-attention mechanism computes:\n",
    "$$\\text{Attention}(Q, K, V) = \\text{softmax}\\left(\\frac{QK^T}{\\sqrt{d_k}}\\right)V$$\n",
    "Without positional encodings, the attention mechanism would treat the sequence as a bag of words — it would have no way to know if a token is first, last, or in between."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acfd9980",
   "metadata": {},
   "source": [
    "## Why Not Feed Position Separately?\n",
    "* You could feed positional information as a separate input, but the original Transformer design simply adds it to the embeddings. This way:\n",
    "* The attention layers don’t need to be modified.\n",
    "Position information is available from the very first layer.\n",
    "### Analogy\n",
    "Think of a transformer as a group of people in a meeting (attention heads).\n",
    "\n",
    "* Token embeddings = what each person is saying.\n",
    "* Positional encoding = a label telling you where each person is sitting around the table.\n",
    "* Attention mechanism = deciding who listens to whom.\n",
    "\n",
    "If you remove the seating labels, people can still hear each other, but they can’t tell who is speaking in what order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5cc1b551",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, dim_model, dropout_p, max_len):\n",
    "        # dim_model → size of each token embedding vector (e.g., 512 in the original Transformer paper).\n",
    "        # dropout_p → probability for dropout to prevent overfitting.\n",
    "        # max_len → maximum sequence length the model will handle.\n",
    "        super().__init__()\n",
    "        # Modified version from: https://pytorch.org/tutorials/beginner/transformer_tutorial.html\n",
    "        # max_len determines how far the position can have an effect on a token (window)\n",
    "        \n",
    "        # After adding positional encodings, we apply dropout for regularization.\n",
    "        self.dropout = nn.Dropout(dropout_p)\n",
    "        \n",
    "        # Encoding - From formula\n",
    "        # We create a matrix of shape (max_len, dim_model) that will store the positional encodings for each position in the sequence.\n",
    "        pos_encoding = torch.zeros(max_len, dim_model)\n",
    "\n",
    "        # Position encoding formula\n",
    "        # Creates a column vector, each row corresponds to the position index in the sequence.\n",
    "        positions_list = torch.arange(0, max_len, dtype=torch.float).view(-1, 1) # 0, 1, 2, 3, 4, 5\n",
    "\n",
    "        # Division term for the positional encoding formula\n",
    "        # This implements the formula from the Transformer paper (sin, cos)\n",
    "        division_term = torch.exp(torch.arange(0, dim_model, 2).float() * (-math.log(10000.0)) / dim_model) # 1000^(2i/dim_model)\n",
    "        # PE(pos, 2i) = sin(pos/1000^(2i/dim_model))\n",
    "        pos_encoding[:, 0::2] = torch.sin(positions_list * division_term)\n",
    "        # PE(pos, 2i + 1) = cos(pos/1000^(2i/dim_model))\n",
    "        pos_encoding[:, 1::2] = torch.cos(positions_list * division_term)\n",
    "        \n",
    "        # Saving buffer (same as parameter without gradients needed)\n",
    "        # Reshape for Batch Compatibility\n",
    "        # unsqueeze(0) → adds a batch dimension at the front.\n",
    "        # transpose(0, 1) → final shape becomes (max_len, 1, dim_model),\n",
    "        # which matches the (sequence_length, batch_size, embedding_dim) format used by PyTorch’s Transformer.\n",
    "        pos_encoding = pos_encoding.unsqueeze(0).transpose(0, 1)\n",
    "\n",
    "        # Buffers are like parameters, but not updated during training.\n",
    "        # This ensures positional encoding is stored with the model and moved to GPU with .to(device), but gradients are not computed for it.\n",
    "        self.register_buffer(\"pos_encoding\",pos_encoding)\n",
    "        \n",
    "    def forward(self, token_embedding: torch.tensor) -> torch.tensor:\n",
    "        # Residual connection + pos encoding\n",
    "        return self.dropout(token_embedding + self.pos_encoding[:token_embedding.size(0), :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ce795da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# --- Create positional encoding ---\n",
    "dim_model = 16   # embedding size\n",
    "max_len = 50     # sequence length\n",
    "pos_enc = PositionalEncoding(dim_model, dropout_p=0.0, max_len=max_len)\n",
    "\n",
    "# Remove batch dimension for plotting\n",
    "pe_matrix = pos_enc.pos_encoding.squeeze(1)  # shape: (max_len, dim_model)\n",
    "\n",
    "# --- Plot heatmap ---\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.imshow(pe_matrix, cmap='viridis', aspect='auto')\n",
    "plt.colorbar(label=\"Positional Encoding Value\")\n",
    "plt.xlabel(\"Embedding Dimension\")\n",
    "plt.ylabel(\"Position in Sequence\")\n",
    "plt.title(\"Positional Encoding Heatmap (Sine/Cosine Waves)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2d446d55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Positional Encoding Matrix (max_len=6, dim_model=4) ===\n",
      "tensor([[ 0.0000,  1.0000,  0.0000,  1.0000],\n",
      "        [ 0.8415,  0.5403,  0.0100,  0.9999],\n",
      "        [ 0.9093, -0.4161,  0.0200,  0.9998],\n",
      "        [ 0.1411, -0.9900,  0.0300,  0.9996],\n",
      "        [-0.7568, -0.6536,  0.0400,  0.9992],\n",
      "        [-0.9589,  0.2837,  0.0500,  0.9988]])\n",
      "\n",
      "=== Output after adding positional encoding (seq_len=3) ===\n",
      "tensor([[ 0.0000,  1.0000,  0.0000,  1.0000],\n",
      "        [ 0.8415,  0.5403,  0.0100,  0.9999],\n",
      "        [ 0.9093, -0.4161,  0.0200,  0.9998]])\n"
     ]
    }
   ],
   "source": [
    "# --- Small test ---\n",
    "torch.set_printoptions(precision=4, sci_mode=False)\n",
    "\n",
    "# Small dimensions for clarity\n",
    "dim_model = 4      # embedding size\n",
    "max_len = 6        # max sequence length\n",
    "dropout_p = 0.0    # turn off dropout for inspection\n",
    "\n",
    "pos_enc = PositionalEncoding(dim_model, dropout_p, max_len)\n",
    "\n",
    "print(\"=== Positional Encoding Matrix (max_len=6, dim_model=4) ===\")\n",
    "print(pos_enc.pos_encoding.squeeze(1))  # shape: (max_len, dim_model)\n",
    "\n",
    "# Dummy token embeddings (seq_len=3, batch_size=1, dim_model=4)\n",
    "dummy_embeddings = torch.zeros(3, 1, dim_model)\n",
    "output = pos_enc(dummy_embeddings)\n",
    "\n",
    "print(\"\\n=== Output after adding positional encoding (seq_len=3) ===\")\n",
    "print(output.squeeze(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e893a803",
   "metadata": {},
   "source": [
    "## Transformer\n",
    "This is a PyTorch module that:\n",
    "\n",
    "* Embeds tokens (words, subwords, etc.)\n",
    "* Adds positional encodings\n",
    "* Passes them through a Transformer encoder-decoder stack\n",
    "* Projects the output back to vocabulary space\n",
    "\n",
    "### Transformer paremeters\n",
    "* num_tokens → vocabulary size (number of unique tokens)\n",
    "* dim_model → embedding size (must match d_model in transformer)\n",
    "* num_heads → number of attention heads\n",
    "* num_encoder_layers → how many encoder layers\n",
    "* num_decoder_layers → how many decoder layers\n",
    "* dropout_p → dropout probability\n",
    "\n",
    "### Forward pass parameters\n",
    "* src → source sequence token IDs (batch_size, src_len)\n",
    "* tgt → target sequence token IDs (batch_size, tgt_len)\n",
    "* tgt_mask → prevents the decoder from looking ahead at future tokens (causal mask)\n",
    "* src_pad_mask / tgt_pad_mask → masks padding tokens so they don’t affect attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6377e527",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):\n",
    "    \"\"\"\n",
    "    Model from \"A detailed guide to Pytorch's nn.Transformer() module.\", by\n",
    "    Daniel Melchor: https://medium.com/@danielmelchor/a-detailed-guide-to-pytorchs-nn-transformer-module-c80afbc9ffb1\n",
    "    \"\"\"\n",
    "    # Constructor\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_tokens,\n",
    "        dim_model,\n",
    "        num_heads,\n",
    "        num_encoder_layers,\n",
    "        num_decoder_layers,\n",
    "        dropout_p,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        # INFO\n",
    "        self.model_type = \"Transformer\"\n",
    "        self.dim_model = dim_model\n",
    "\n",
    "        # LAYERS\n",
    "        # Positional encoding (above)\n",
    "        self.positional_encoder = PositionalEncoding(\n",
    "            dim_model=dim_model, dropout_p=dropout_p, max_len=5000\n",
    "        )\n",
    "        # Token Embedding\n",
    "        # Converts token IDs into dense vectors of size dim_model.\n",
    "        self.embedding = nn.Embedding(num_tokens, dim_model)\n",
    "\n",
    "        # Transformer\n",
    "        self.transformer = nn.Transformer(\n",
    "            d_model=dim_model,\n",
    "            nhead=num_heads,\n",
    "            num_encoder_layers=num_encoder_layers,\n",
    "            num_decoder_layers=num_decoder_layers,\n",
    "            dropout=dropout_p,\n",
    "        )\n",
    "\n",
    "        # Final projection from hidden dimension → vocabulary size.\n",
    "        # Converts the Transformer output back into logits for each token. Output layer.\n",
    "        self.out = nn.Linear(dim_model, num_tokens)\n",
    "        \n",
    "    def forward(self, src, tgt, tgt_mask=None, src_pad_mask=None, tgt_pad_mask=None):\n",
    "        # Src size must be (batch_size, src sequence length)\n",
    "        # Tgt size must be (batch_size, tgt sequence length)\n",
    "\n",
    "        # Embedding + positional encoding - Out size = (batch_size, sequence length, dim_model)\n",
    "        # Scales them by sqrt(dim_model) to keep variance stable (from the paper)\n",
    "        src = self.embedding(src) * math.sqrt(self.dim_model)\n",
    "        tgt = self.embedding(tgt) * math.sqrt(self.dim_model)\n",
    "\n",
    "        # Adds positional encoding\n",
    "        src = self.positional_encoder(src)\n",
    "        tgt = self.positional_encoder(tgt)\n",
    "        \n",
    "        # We could use the parameter batch_first=True, but our KDL version doesn't support it yet, so we permute\n",
    "        # to obtain size (sequence length, batch_size, dim_model),\n",
    "        # Swap axes to what nn.Transformer expects\n",
    "        src = src.permute(1,0,2)\n",
    "        tgt = tgt.permute(1,0,2)\n",
    "\n",
    "        # Transformer blocks - Out size = (sequence length, batch_size, num_tokens)\n",
    "        # Encoder processes src (self-attention + feed-forward).\n",
    "        # Decoder processes tgt (masked self-attention + cross-attention with encoder output).\n",
    "        transformer_out = self.transformer(src, tgt, tgt_mask=tgt_mask, src_key_padding_mask=src_pad_mask, tgt_key_padding_mask=tgt_pad_mask)\n",
    "        out = self.out(transformer_out)\n",
    "        \n",
    "        return out\n",
    "      \n",
    "    def get_tgt_mask(self, size) -> torch.tensor:\n",
    "        # Generates a square matrix where the each row allows one word more to be seen\n",
    "        # Creates a causal mask for the decoder:\n",
    "        # Lower triangular matrix = each position can only attend to itself and previous positions.\n",
    "        # 0.0 means allowed, -inf means blocked (softmax will ignore these).\n",
    "\n",
    "        mask = torch.tril(torch.ones(size, size) == 1) # Lower triangular matrix\n",
    "        mask = mask.float()\n",
    "        mask = mask.masked_fill(mask == 0, float('-inf')) # Convert zeros to -inf\n",
    "        mask = mask.masked_fill(mask == 1, float(0.0)) # Convert ones to 0\n",
    "        \n",
    "        # EX for size=5:\n",
    "        # [[0., -inf, -inf, -inf, -inf],\n",
    "        #  [0.,   0., -inf, -inf, -inf],\n",
    "        #  [0.,   0.,   0., -inf, -inf],\n",
    "        #  [0.,   0.,   0.,   0., -inf],\n",
    "        #  [0.,   0.,   0.,   0.,   0.]]\n",
    "        \n",
    "        return mask\n",
    "    \n",
    "    def create_pad_mask(self, matrix: torch.tensor, pad_token: int) -> torch.tensor:\n",
    "        # If matrix = [1,2,3,0,0,0] where pad_token=0, the result mask is\n",
    "        # [False, False, False, True, True, True]\n",
    "        return (matrix == pad_token)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37fea447",
   "metadata": {},
   "source": [
    "# Data generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b97949c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "562 batches of size 16\n",
      "187 batches of size 16\n"
     ]
    }
   ],
   "source": [
    "def generate_random_data(n):\n",
    "    SOS_token = np.array([2])\n",
    "    EOS_token = np.array([3])\n",
    "    length = 8\n",
    "\n",
    "    data = []\n",
    "\n",
    "    # 1,1,1,1,1,1 -> 1,1,1,1,1\n",
    "    for i in range(n // 3):\n",
    "        X = np.concatenate((SOS_token, np.ones(length), EOS_token))\n",
    "        y = np.concatenate((SOS_token, np.ones(length), EOS_token))\n",
    "        data.append([X, y])\n",
    "\n",
    "    # 0,0,0,0 -> 0,0,0,0\n",
    "    for i in range(n // 3):\n",
    "        X = np.concatenate((SOS_token, np.zeros(length), EOS_token))\n",
    "        y = np.concatenate((SOS_token, np.zeros(length), EOS_token))\n",
    "        data.append([X, y])\n",
    "\n",
    "    # 1,0,1,0 -> 1,0,1,0,1\n",
    "    for i in range(n // 3):\n",
    "        X = np.zeros(length)\n",
    "        start = random.randint(0, 1)\n",
    "\n",
    "        X[start::2] = 1\n",
    "\n",
    "        y = np.zeros(length)\n",
    "        if X[-1] == 0:\n",
    "            y[::2] = 1\n",
    "        else:\n",
    "            y[1::2] = 1\n",
    "\n",
    "        X = np.concatenate((SOS_token, X, EOS_token))\n",
    "        y = np.concatenate((SOS_token, y, EOS_token))\n",
    "\n",
    "        data.append([X, y])\n",
    "\n",
    "    np.random.shuffle(data)\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "def batchify_data(data, batch_size=16, padding=False, padding_token=-1):\n",
    "    batches = []\n",
    "    for idx in range(0, len(data), batch_size):\n",
    "        # We make sure we dont get the last bit if its not batch_size size\n",
    "        if idx + batch_size < len(data):\n",
    "            # Here you would need to get the max length of the batch,\n",
    "            # and normalize the length with the PAD token.\n",
    "            if padding:\n",
    "                max_batch_length = 0\n",
    "\n",
    "                # Get longest sentence in batch\n",
    "                for seq in data[idx : idx + batch_size]:\n",
    "                    if len(seq) > max_batch_length:\n",
    "                        max_batch_length = len(seq)\n",
    "\n",
    "                # Append X padding tokens until it reaches the max length\n",
    "                for seq_idx in range(batch_size):\n",
    "                    remaining_length = max_bath_length - len(data[idx + seq_idx])\n",
    "                    data[idx + seq_idx] += [padding_token] * remaining_length\n",
    "\n",
    "            batches.append(np.array(data[idx : idx + batch_size]).astype(np.int64))\n",
    "\n",
    "    print(f\"{len(batches)} batches of size {batch_size}\")\n",
    "\n",
    "    return batches\n",
    "\n",
    "\n",
    "train_data = generate_random_data(9000)\n",
    "val_data = generate_random_data(3000)\n",
    "\n",
    "train_dataloader = batchify_data(train_data)\n",
    "val_dataloader = batchify_data(val_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59f70e91",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f89bc10a",
   "metadata": {},
   "source": [
    "A note about dropout\n",
    "\n",
    "Dropout is a regularization technique that helps prevent overfitting.\n",
    "\n",
    "During training only (not inference), dropout randomly sets some fraction (dropout_p) of the elements in a tensor to zero.\n",
    "The remaining elements are scaled up so that the overall expected sum stays the same.\n",
    "This forces the network to not rely too heavily on any single neuron/feature, encouraging more robust feature learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "005ada82",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jdtibochab/miniforge3/envs/transformers/lib/python3.9/site-packages/torch/nn/modules/transformer.py:392: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = Transformer(\n",
    "    num_tokens=4, dim_model=8, num_heads=2, num_encoder_layers=3, num_decoder_layers=3, dropout_p=0.1\n",
    ").to(device)\n",
    "opt = torch.optim.SGD(model.parameters(), lr=0.01)\n",
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e431a03b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(model, opt, loss_fn, dataloader):\n",
    "    \"\"\"\n",
    "    Method from \"A detailed guide to Pytorch's nn.Transformer() module.\", by\n",
    "    Daniel Melchor: https://medium.com/@danielmelchor/a-detailed-guide-to-pytorchs-nn-transformer-module-c80afbc9ffb1\n",
    "    \"\"\"\n",
    "    \n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    \n",
    "    for batch in dataloader:\n",
    "        X, y = batch[:, 0], batch[:, 1]\n",
    "        X, y = torch.tensor(X).to(device), torch.tensor(y).to(device)\n",
    "\n",
    "        # Now we shift the tgt by one so with the <SOS> we predict the token at pos 1\n",
    "        y_input = y[:,:-1]\n",
    "        y_expected = y[:,1:]\n",
    "        \n",
    "        # Get mask to mask out the next words\n",
    "        sequence_length = y_input.size(1)\n",
    "        tgt_mask = model.get_tgt_mask(sequence_length).to(device)\n",
    "\n",
    "        # Standard training except we pass in y_input and tgt_mask\n",
    "        pred = model(X, y_input, tgt_mask)\n",
    "\n",
    "        # Permute pred to have batch size first again\n",
    "        pred = pred.permute(1, 2, 0)      \n",
    "        loss = loss_fn(pred, y_expected)\n",
    "\n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "    \n",
    "        total_loss += loss.detach().item()\n",
    "        \n",
    "    return total_loss / len(dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1cd033f",
   "metadata": {},
   "source": [
    "# Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f1f30015",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation_loop(model, loss_fn, dataloader):\n",
    "    \"\"\"\n",
    "    Method from \"A detailed guide to Pytorch's nn.Transformer() module.\", by\n",
    "    Daniel Melchor: https://medium.com/@danielmelchor/a-detailed-guide-to-pytorchs-nn-transformer-module-c80afbc9ffb1\n",
    "    \"\"\"\n",
    "    \n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            X, y = batch[:, 0], batch[:, 1]\n",
    "            X, y = torch.tensor(X, dtype=torch.long, device=device), torch.tensor(y, dtype=torch.long, device=device)\n",
    "\n",
    "            # Now we shift the tgt by one so with the <SOS> we predict the token at pos 1\n",
    "            y_input = y[:,:-1]\n",
    "            y_expected = y[:,1:]\n",
    "            \n",
    "            # Get mask to mask out the next words\n",
    "            sequence_length = y_input.size(1)\n",
    "            tgt_mask = model.get_tgt_mask(sequence_length).to(device)\n",
    "\n",
    "            # Standard training except we pass in y_input and src_mask\n",
    "            pred = model(X, y_input, tgt_mask)\n",
    "\n",
    "            # Permute pred to have batch size first again\n",
    "            pred = pred.permute(1, 2, 0)      \n",
    "            loss = loss_fn(pred, y_expected)\n",
    "            total_loss += loss.detach().item()\n",
    "        \n",
    "    return total_loss / len(dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b2c0963",
   "metadata": {},
   "source": [
    "# Fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3d41112c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training and validating model\n",
      "------------------------- Epoch 1 -------------------------\n",
      "Training loss: 0.5839\n",
      "Validation loss: 0.4187\n",
      "\n",
      "------------------------- Epoch 2 -------------------------\n",
      "Training loss: 0.4230\n",
      "Validation loss: 0.3942\n",
      "\n",
      "------------------------- Epoch 3 -------------------------\n",
      "Training loss: 0.4019\n",
      "Validation loss: 0.3771\n",
      "\n",
      "------------------------- Epoch 4 -------------------------\n",
      "Training loss: 0.3854\n",
      "Validation loss: 0.3568\n",
      "\n",
      "------------------------- Epoch 5 -------------------------\n",
      "Training loss: 0.3670\n",
      "Validation loss: 0.3328\n",
      "\n",
      "------------------------- Epoch 6 -------------------------\n",
      "Training loss: 0.3492\n",
      "Validation loss: 0.3034\n",
      "\n",
      "------------------------- Epoch 7 -------------------------\n",
      "Training loss: 0.3296\n",
      "Validation loss: 0.2743\n",
      "\n",
      "------------------------- Epoch 8 -------------------------\n",
      "Training loss: 0.3132\n",
      "Validation loss: 0.2568\n",
      "\n",
      "------------------------- Epoch 9 -------------------------\n",
      "Training loss: 0.3011\n",
      "Validation loss: 0.2365\n",
      "\n",
      "------------------------- Epoch 10 -------------------------\n",
      "Training loss: 0.2850\n",
      "Validation loss: 0.2176\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def fit(model, opt, loss_fn, train_dataloader, val_dataloader, epochs):\n",
    "    \"\"\"\n",
    "    Method from \"A detailed guide to Pytorch's nn.Transformer() module.\", by\n",
    "    Daniel Melchor: https://medium.com/@danielmelchor/a-detailed-guide-to-pytorchs-nn-transformer-module-c80afbc9ffb1\n",
    "    \"\"\"\n",
    "    \n",
    "    # Used for plotting later on\n",
    "    train_loss_list, validation_loss_list = [], []\n",
    "    \n",
    "    print(\"Training and validating model\")\n",
    "    for epoch in range(epochs):\n",
    "        print(\"-\"*25, f\"Epoch {epoch + 1}\",\"-\"*25)\n",
    "        \n",
    "        train_loss = train_loop(model, opt, loss_fn, train_dataloader)\n",
    "        train_loss_list += [train_loss]\n",
    "        \n",
    "        validation_loss = validation_loop(model, loss_fn, val_dataloader)\n",
    "        validation_loss_list += [validation_loss]\n",
    "        \n",
    "        print(f\"Training loss: {train_loss:.4f}\")\n",
    "        print(f\"Validation loss: {validation_loss:.4f}\")\n",
    "        print()\n",
    "        \n",
    "    return train_loss_list, validation_loss_list\n",
    "    \n",
    "train_loss_list, validation_loss_list = fit(model, opt, loss_fn, train_dataloader, val_dataloader, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "571b13ff",
   "metadata": {},
   "source": [
    "# Predicting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ed7f8142",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example 0\n",
      "Input: [0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Continuation: [0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "\n",
      "Example 1\n",
      "Input: [1, 1, 1, 1, 1, 1, 1, 1]\n",
      "Continuation: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "\n",
      "Example 2\n",
      "Input: [1, 0, 1, 0, 1, 0, 1, 0]\n",
      "Continuation: [1, 0, 1, 0, 1, 0, 1, 0, 1, 0]\n",
      "\n",
      "Example 3\n",
      "Input: [0, 1, 0, 1, 0, 1, 0, 1]\n",
      "Continuation: [1, 0, 1, 0, 1, 0, 1, 0, 1, 0]\n",
      "\n",
      "Example 4\n",
      "Input: [0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0]\n",
      "Continuation: [0, 1, 0, 1, 0, 1, 0, 1, 0]\n",
      "\n",
      "Example 5\n",
      "Input: [0, 1]\n",
      "Continuation: [0, 1, 0, 1, 0, 1, 0, 1, 0]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def predict(model, input_sequence, max_length=15, SOS_token=2, EOS_token=3):\n",
    "    \"\"\"\n",
    "    Method from \"A detailed guide to Pytorch's nn.Transformer() module.\", by\n",
    "    Daniel Melchor: https://medium.com/@danielmelchor/a-detailed-guide-to-pytorchs-nn-transformer-module-c80afbc9ffb1\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    y_input = torch.tensor([[SOS_token]], dtype=torch.long, device=device)\n",
    "\n",
    "    num_tokens = len(input_sequence[0])\n",
    "\n",
    "    for _ in range(max_length):\n",
    "        # Get source mask\n",
    "        tgt_mask = model.get_tgt_mask(y_input.size(1)).to(device)\n",
    "        \n",
    "        pred = model(input_sequence, y_input, tgt_mask)\n",
    "        \n",
    "        next_item = pred.topk(1)[1].view(-1)[-1].item() # num with highest probability\n",
    "        next_item = torch.tensor([[next_item]], device=device)\n",
    "\n",
    "        # Concatenate previous input with predicted best word\n",
    "        y_input = torch.cat((y_input, next_item), dim=1)\n",
    "\n",
    "        # Stop if model predicts end of sentence\n",
    "        if next_item.view(-1).item() == EOS_token:\n",
    "            break\n",
    "\n",
    "    return y_input.view(-1).tolist()\n",
    "  \n",
    "  \n",
    "# Here we test some examples to observe how the model predicts\n",
    "examples = [\n",
    "    torch.tensor([[2, 0, 0, 0, 0, 0, 0, 0, 0, 3]], dtype=torch.long, device=device),\n",
    "    torch.tensor([[2, 1, 1, 1, 1, 1, 1, 1, 1, 3]], dtype=torch.long, device=device),\n",
    "    torch.tensor([[2, 1, 0, 1, 0, 1, 0, 1, 0, 3]], dtype=torch.long, device=device),\n",
    "    torch.tensor([[2, 0, 1, 0, 1, 0, 1, 0, 1, 3]], dtype=torch.long, device=device),\n",
    "    torch.tensor([[2, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 3]], dtype=torch.long, device=device),\n",
    "    torch.tensor([[2, 0, 1, 3]], dtype=torch.long, device=device)\n",
    "]\n",
    "\n",
    "for idx, example in enumerate(examples):\n",
    "    result = predict(model, example)\n",
    "    print(f\"Example {idx}\")\n",
    "    print(f\"Input: {example.view(-1).tolist()[1:-1]}\")\n",
    "    print(f\"Continuation: {result[1:-1]}\")\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "transformers",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
