{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/ramanathanlab/genslm/blob/main/examples/embedding.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YZ6uvXc6DDpG",
    "outputId": "48febbf8-0472-4811-abd1-cdaf5f95cff9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/ramanathanlab/genslm\n",
      "  Cloning https://github.com/ramanathanlab/genslm to /private/var/folders/kb/4rj6v4lj55b0h_wrblbl2pt80000gp/T/pip-req-build-rug63m21\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/ramanathanlab/genslm /private/var/folders/kb/4rj6v4lj55b0h_wrblbl2pt80000gp/T/pip-req-build-rug63m21\n",
      "  Resolved https://github.com/ramanathanlab/genslm to commit e4fbf3b8e641150d708c18e12d551de8ed0cae1c\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting transformers@ git+https://github.com/maxzvyagin/transformers (from genslm==0.0.4a1)\n",
      "  Cloning https://github.com/maxzvyagin/transformers to /private/var/folders/kb/4rj6v4lj55b0h_wrblbl2pt80000gp/T/pip-install-7xj2wut8/transformers_6c83181bd23742ddb3229187a99a18fb\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/maxzvyagin/transformers /private/var/folders/kb/4rj6v4lj55b0h_wrblbl2pt80000gp/T/pip-install-7xj2wut8/transformers_6c83181bd23742ddb3229187a99a18fb\n",
      "  Resolved https://github.com/maxzvyagin/transformers to commit ffd5aba0ad41a1ebd1897a77f6a3782fc2d75e1f\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting pytorch-lightning==1.6.5 (from genslm==0.0.4a1)\n",
      "  Using cached pytorch_lightning-1.6.5-py3-none-any.whl.metadata (32 kB)\n",
      "Collecting wandb (from genslm==0.0.4a1)\n",
      "  Using cached wandb-0.21.1-py3-none-macosx_11_0_arm64.whl.metadata (10 kB)\n",
      "Collecting pydantic==1.10.2 (from genslm==0.0.4a1)\n",
      "  Using cached pydantic-1.10.2-cp39-cp39-macosx_11_0_arm64.whl.metadata (140 kB)\n",
      "Collecting biopython==1.79 (from genslm==0.0.4a1)\n",
      "  Using cached biopython-1.79-cp39-cp39-macosx_11_0_arm64.whl\n",
      "Collecting pandas (from genslm==0.0.4a1)\n",
      "  Using cached pandas-2.3.2-cp39-cp39-macosx_11_0_arm64.whl.metadata (91 kB)\n",
      "Collecting natsort (from genslm==0.0.4a1)\n",
      "  Using cached natsort-8.4.0-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting Jinja2 (from genslm==0.0.4a1)\n",
      "  Using cached jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting h5py==3.7.0 (from genslm==0.0.4a1)\n",
      "  Using cached h5py-3.7.0-cp39-cp39-macosx_11_0_arm64.whl.metadata (1.8 kB)\n",
      "Collecting lightning-transformers==0.2.1 (from genslm==0.0.4a1)\n",
      "  Using cached lightning_transformers-0.2.1-py3-none-any.whl.metadata (7.9 kB)\n",
      "Requirement already satisfied: numpy in /Users/jdtibochab/miniforge3/envs/genslm/lib/python3.9/site-packages (from biopython==1.79->genslm==0.0.4a1) (2.0.2)\n",
      "Collecting torch>=1.10.0 (from lightning-transformers==0.2.1->genslm==0.0.4a1)\n",
      "  Using cached torch-2.8.0-cp39-none-macosx_11_0_arm64.whl.metadata (30 kB)\n",
      "Requirement already satisfied: tqdm in /Users/jdtibochab/miniforge3/envs/genslm/lib/python3.9/site-packages (from lightning-transformers==0.2.1->genslm==0.0.4a1) (4.67.1)\n",
      "Collecting torchmetrics>=0.7.0 (from lightning-transformers==0.2.1->genslm==0.0.4a1)\n",
      "  Using cached torchmetrics-1.8.1-py3-none-any.whl.metadata (22 kB)\n",
      "Collecting datasets (from lightning-transformers==0.2.1->genslm==0.0.4a1)\n",
      "  Using cached datasets-4.0.0-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting sentencepiece (from lightning-transformers==0.2.1->genslm==0.0.4a1)\n",
      "  Using cached sentencepiece-0.2.1-cp39-cp39-macosx_11_0_arm64.whl.metadata (10 kB)\n",
      "Collecting Pillow (from lightning-transformers==0.2.1->genslm==0.0.4a1)\n",
      "  Using cached pillow-11.3.0-cp39-cp39-macosx_11_0_arm64.whl.metadata (9.0 kB)\n",
      "Collecting protobuf==3.20.1 (from lightning-transformers==0.2.1->genslm==0.0.4a1)\n",
      "  Using cached protobuf-3.20.1-py2.py3-none-any.whl.metadata (720 bytes)\n",
      "Requirement already satisfied: typing-extensions>=4.1.0 in /Users/jdtibochab/miniforge3/envs/genslm/lib/python3.9/site-packages (from pydantic==1.10.2->genslm==0.0.4a1) (4.15.0)\n",
      "Requirement already satisfied: PyYAML>=5.4 in /Users/jdtibochab/miniforge3/envs/genslm/lib/python3.9/site-packages (from pytorch-lightning==1.6.5->genslm==0.0.4a1) (6.0.2)\n",
      "Requirement already satisfied: fsspec!=2021.06.0,>=2021.05.0 in /Users/jdtibochab/miniforge3/envs/genslm/lib/python3.9/site-packages (from fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.6.5->genslm==0.0.4a1) (2025.7.0)\n",
      "Collecting tensorboard>=2.2.0 (from pytorch-lightning==1.6.5->genslm==0.0.4a1)\n",
      "  Using cached tensorboard-2.20.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting pyDeprecate>=0.3.1 (from pytorch-lightning==1.6.5->genslm==0.0.4a1)\n",
      "  Using cached pyDeprecate-0.3.2-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: packaging>=17.0 in /Users/jdtibochab/miniforge3/envs/genslm/lib/python3.9/site-packages (from pytorch-lightning==1.6.5->genslm==0.0.4a1) (25.0)\n",
      "Requirement already satisfied: filelock in /Users/jdtibochab/miniforge3/envs/genslm/lib/python3.9/site-packages (from transformers@ git+https://github.com/maxzvyagin/transformers->genslm==0.0.4a1) (3.19.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /Users/jdtibochab/miniforge3/envs/genslm/lib/python3.9/site-packages (from transformers@ git+https://github.com/maxzvyagin/transformers->genslm==0.0.4a1) (0.34.4)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/jdtibochab/miniforge3/envs/genslm/lib/python3.9/site-packages (from transformers@ git+https://github.com/maxzvyagin/transformers->genslm==0.0.4a1) (2025.7.34)\n",
      "Requirement already satisfied: requests in /Users/jdtibochab/miniforge3/envs/genslm/lib/python3.9/site-packages (from transformers@ git+https://github.com/maxzvyagin/transformers->genslm==0.0.4a1) (2.32.5)\n",
      "Collecting tokenizers!=0.11.3,<0.13,>=0.11.1 (from transformers@ git+https://github.com/maxzvyagin/transformers->genslm==0.0.4a1)\n",
      "  Using cached tokenizers-0.12.1.tar.gz (220 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting MarkupSafe>=2.0 (from Jinja2->genslm==0.0.4a1)\n",
      "  Using cached MarkupSafe-3.0.2-cp39-cp39-macosx_11_0_arm64.whl.metadata (4.0 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/jdtibochab/miniforge3/envs/genslm/lib/python3.9/site-packages (from pandas->genslm==0.0.4a1) (2.9.0.post0)\n",
      "Collecting pytz>=2020.1 (from pandas->genslm==0.0.4a1)\n",
      "  Using cached pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas->genslm==0.0.4a1)\n",
      "  Using cached tzdata-2025.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting click!=8.0.0,>=7.1 (from wandb->genslm==0.0.4a1)\n",
      "  Using cached click-8.1.8-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting eval-type-backport (from wandb->genslm==0.0.4a1)\n",
      "  Using cached eval_type_backport-0.2.2-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting gitpython!=3.1.29,>=1.0.0 (from wandb->genslm==0.0.4a1)\n",
      "  Using cached gitpython-3.1.45-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: platformdirs in /Users/jdtibochab/miniforge3/envs/genslm/lib/python3.9/site-packages (from wandb->genslm==0.0.4a1) (4.4.0)\n",
      "Collecting sentry-sdk>=2.0.0 (from wandb->genslm==0.0.4a1)\n",
      "  Using cached sentry_sdk-2.35.1-py2.py3-none-any.whl.metadata (10 kB)\n",
      "Collecting aiohttp!=4.0.0a0,!=4.0.0a1 (from fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.6.5->genslm==0.0.4a1)\n",
      "  Using cached aiohttp-3.12.15-cp39-cp39-macosx_11_0_arm64.whl.metadata (7.7 kB)\n",
      "Collecting gitdb<5,>=4.0.1 (from gitpython!=3.1.29,>=1.0.0->wandb->genslm==0.0.4a1)\n",
      "  Using cached gitdb-4.0.12-py3-none-any.whl.metadata (1.2 kB)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /Users/jdtibochab/miniforge3/envs/genslm/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.1.0->transformers@ git+https://github.com/maxzvyagin/transformers->genslm==0.0.4a1) (1.1.8)\n",
      "Requirement already satisfied: six>=1.5 in /Users/jdtibochab/miniforge3/envs/genslm/lib/python3.9/site-packages (from python-dateutil>=2.8.2->pandas->genslm==0.0.4a1) (1.17.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/jdtibochab/miniforge3/envs/genslm/lib/python3.9/site-packages (from requests->transformers@ git+https://github.com/maxzvyagin/transformers->genslm==0.0.4a1) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/jdtibochab/miniforge3/envs/genslm/lib/python3.9/site-packages (from requests->transformers@ git+https://github.com/maxzvyagin/transformers->genslm==0.0.4a1) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/jdtibochab/miniforge3/envs/genslm/lib/python3.9/site-packages (from requests->transformers@ git+https://github.com/maxzvyagin/transformers->genslm==0.0.4a1) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/jdtibochab/miniforge3/envs/genslm/lib/python3.9/site-packages (from requests->transformers@ git+https://github.com/maxzvyagin/transformers->genslm==0.0.4a1) (2025.8.3)\n",
      "Collecting absl-py>=0.4 (from tensorboard>=2.2.0->pytorch-lightning==1.6.5->genslm==0.0.4a1)\n",
      "  Using cached absl_py-2.3.1-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting grpcio>=1.48.2 (from tensorboard>=2.2.0->pytorch-lightning==1.6.5->genslm==0.0.4a1)\n",
      "  Using cached grpcio-1.74.0-cp39-cp39-macosx_11_0_universal2.whl.metadata (3.8 kB)\n",
      "Collecting markdown>=2.6.8 (from tensorboard>=2.2.0->pytorch-lightning==1.6.5->genslm==0.0.4a1)\n",
      "  Using cached markdown-3.8.2-py3-none-any.whl.metadata (5.1 kB)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /Users/jdtibochab/miniforge3/envs/genslm/lib/python3.9/site-packages (from tensorboard>=2.2.0->pytorch-lightning==1.6.5->genslm==0.0.4a1) (80.9.0)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard>=2.2.0->pytorch-lightning==1.6.5->genslm==0.0.4a1)\n",
      "  Using cached tensorboard_data_server-0.7.2-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting werkzeug>=1.0.1 (from tensorboard>=2.2.0->pytorch-lightning==1.6.5->genslm==0.0.4a1)\n",
      "  Using cached werkzeug-3.1.3-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting sympy>=1.13.3 (from torch>=1.10.0->lightning-transformers==0.2.1->genslm==0.0.4a1)\n",
      "  Using cached sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting networkx (from torch>=1.10.0->lightning-transformers==0.2.1->genslm==0.0.4a1)\n",
      "  Using cached networkx-3.2.1-py3-none-any.whl.metadata (5.2 kB)\n",
      "Collecting lightning-utilities>=0.8.0 (from torchmetrics>=0.7.0->lightning-transformers==0.2.1->genslm==0.0.4a1)\n",
      "  Using cached lightning_utilities-0.15.2-py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting pyarrow>=15.0.0 (from datasets->lightning-transformers==0.2.1->genslm==0.0.4a1)\n",
      "  Using cached pyarrow-21.0.0-cp39-cp39-macosx_12_0_arm64.whl.metadata (3.3 kB)\n",
      "Collecting dill<0.3.9,>=0.3.0 (from datasets->lightning-transformers==0.2.1->genslm==0.0.4a1)\n",
      "  Using cached dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting xxhash (from datasets->lightning-transformers==0.2.1->genslm==0.0.4a1)\n",
      "  Using cached xxhash-3.5.0-cp39-cp39-macosx_11_0_arm64.whl.metadata (12 kB)\n",
      "Collecting multiprocess<0.70.17 (from datasets->lightning-transformers==0.2.1->genslm==0.0.4a1)\n",
      "  Using cached multiprocess-0.70.16-py39-none-any.whl.metadata (7.2 kB)\n",
      "INFO: pip is looking at multiple versions of datasets to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting datasets (from lightning-transformers==0.2.1->genslm==0.0.4a1)\n",
      "  Using cached datasets-3.6.0-py3-none-any.whl.metadata (19 kB)\n",
      "  Using cached datasets-3.5.1-py3-none-any.whl.metadata (19 kB)\n",
      "  Using cached datasets-3.5.0-py3-none-any.whl.metadata (19 kB)\n",
      "  Using cached datasets-3.4.1-py3-none-any.whl.metadata (19 kB)\n",
      "  Using cached datasets-3.4.0-py3-none-any.whl.metadata (19 kB)\n",
      "  Using cached datasets-3.3.2-py3-none-any.whl.metadata (19 kB)\n",
      "  Using cached datasets-3.3.1-py3-none-any.whl.metadata (19 kB)\n",
      "INFO: pip is still looking at multiple versions of datasets to determine which version is compatible with other requirements. This could take a while.\n",
      "  Using cached datasets-3.3.0-py3-none-any.whl.metadata (19 kB)\n",
      "  Using cached datasets-3.2.0-py3-none-any.whl.metadata (20 kB)\n",
      "  Using cached datasets-3.1.0-py3-none-any.whl.metadata (20 kB)\n",
      "  Using cached datasets-3.0.2-py3-none-any.whl.metadata (20 kB)\n",
      "  Using cached datasets-3.0.1-py3-none-any.whl.metadata (20 kB)\n",
      "Collecting multiprocess (from datasets->lightning-transformers==0.2.1->genslm==0.0.4a1)\n",
      "  Using cached multiprocess-0.70.18-py39-none-any.whl.metadata (7.5 kB)\n",
      "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
      "Collecting datasets (from lightning-transformers==0.2.1->genslm==0.0.4a1)\n",
      "  Using cached datasets-3.0.0-py3-none-any.whl.metadata (19 kB)\n",
      "  Using cached datasets-2.21.0-py3-none-any.whl.metadata (21 kB)\n",
      "  Using cached datasets-2.20.0-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting pyarrow-hotfix (from datasets->lightning-transformers==0.2.1->genslm==0.0.4a1)\n",
      "  Using cached pyarrow_hotfix-0.7-py3-none-any.whl.metadata (3.6 kB)\n",
      "Collecting datasets (from lightning-transformers==0.2.1->genslm==0.0.4a1)\n",
      "  Using cached datasets-2.19.2-py3-none-any.whl.metadata (19 kB)\n",
      "  Using cached datasets-2.19.1-py3-none-any.whl.metadata (19 kB)\n",
      "  Using cached datasets-2.19.0-py3-none-any.whl.metadata (19 kB)\n",
      "  Using cached datasets-2.18.0-py3-none-any.whl.metadata (20 kB)\n",
      "  Using cached datasets-2.17.1-py3-none-any.whl.metadata (20 kB)\n",
      "  Using cached datasets-2.17.0-py3-none-any.whl.metadata (20 kB)\n",
      "  Using cached datasets-2.16.1-py3-none-any.whl.metadata (20 kB)\n",
      "Collecting dill<0.3.8,>=0.3.0 (from datasets->lightning-transformers==0.2.1->genslm==0.0.4a1)\n",
      "  Using cached dill-0.3.7-py3-none-any.whl.metadata (9.9 kB)\n",
      "Collecting datasets (from lightning-transformers==0.2.1->genslm==0.0.4a1)\n",
      "  Using cached datasets-2.16.0-py3-none-any.whl.metadata (20 kB)\n",
      "  Using cached datasets-2.15.0-py3-none-any.whl.metadata (20 kB)\n",
      "  Using cached datasets-2.14.7-py3-none-any.whl.metadata (19 kB)\n",
      "  Using cached datasets-2.14.6-py3-none-any.whl.metadata (19 kB)\n",
      "  Using cached datasets-2.14.5-py3-none-any.whl.metadata (19 kB)\n",
      "  Using cached datasets-2.14.4-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting ipadic>=1.0.0 (from torchmetrics[text]->lightning-transformers==0.2.1->genslm==0.0.4a1)\n",
      "  Using cached ipadic-1.0.0-py3-none-any.whl\n",
      "Collecting nltk>3.8.1 (from torchmetrics[text]->lightning-transformers==0.2.1->genslm==0.0.4a1)\n",
      "  Using cached nltk-3.9.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting mecab-python3>=1.0.6 (from torchmetrics[text]->lightning-transformers==0.2.1->genslm==0.0.4a1)\n",
      "  Using cached mecab_python3-1.0.10-cp39-cp39-macosx_11_0_arm64.whl.metadata (6.2 kB)\n",
      "INFO: pip is looking at multiple versions of torchmetrics[text] to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting torchmetrics[text] (from lightning-transformers==0.2.1->genslm==0.0.4a1)\n",
      "  Using cached torchmetrics-1.8.0-py3-none-any.whl.metadata (21 kB)\n",
      "  Using cached torchmetrics-1.7.4-py3-none-any.whl.metadata (21 kB)\n",
      "  Using cached torchmetrics-1.7.3-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting aiohappyeyeballs>=2.5.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.6.5->genslm==0.0.4a1)\n",
      "  Using cached aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting aiosignal>=1.4.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.6.5->genslm==0.0.4a1)\n",
      "  Using cached aiosignal-1.4.0-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting async-timeout<6.0,>=4.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.6.5->genslm==0.0.4a1)\n",
      "  Using cached async_timeout-5.0.1-py3-none-any.whl.metadata (5.1 kB)\n",
      "Collecting attrs>=17.3.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.6.5->genslm==0.0.4a1)\n",
      "  Using cached attrs-25.3.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.6.5->genslm==0.0.4a1)\n",
      "  Using cached frozenlist-1.7.0-cp39-cp39-macosx_11_0_arm64.whl.metadata (18 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.6.5->genslm==0.0.4a1)\n",
      "  Using cached multidict-6.6.4-cp39-cp39-macosx_11_0_arm64.whl.metadata (5.3 kB)\n",
      "Collecting propcache>=0.2.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.6.5->genslm==0.0.4a1)\n",
      "  Using cached propcache-0.3.2-cp39-cp39-macosx_11_0_arm64.whl.metadata (12 kB)\n",
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.6.5->genslm==0.0.4a1)\n",
      "  Using cached yarl-1.20.1-cp39-cp39-macosx_11_0_arm64.whl.metadata (73 kB)\n",
      "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb->genslm==0.0.4a1)\n",
      "  Using cached smmap-5.0.2-py3-none-any.whl.metadata (4.3 kB)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /Users/jdtibochab/miniforge3/envs/genslm/lib/python3.9/site-packages (from markdown>=2.6.8->tensorboard>=2.2.0->pytorch-lightning==1.6.5->genslm==0.0.4a1) (8.7.0)\n",
      "Collecting joblib (from nltk>3.8.1->torchmetrics[text]->lightning-transformers==0.2.1->genslm==0.0.4a1)\n",
      "  Using cached joblib-1.5.1-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy>=1.13.3->torch>=1.10.0->lightning-transformers==0.2.1->genslm==0.0.4a1)\n",
      "  Using cached mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "INFO: pip is looking at multiple versions of multiprocess to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting multiprocess (from datasets->lightning-transformers==0.2.1->genslm==0.0.4a1)\n",
      "  Using cached multiprocess-0.70.17-py39-none-any.whl.metadata (7.2 kB)\n",
      "  Using cached multiprocess-0.70.15-py39-none-any.whl.metadata (7.2 kB)\n",
      "Requirement already satisfied: zipp>=3.20 in /Users/jdtibochab/miniforge3/envs/genslm/lib/python3.9/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard>=2.2.0->pytorch-lightning==1.6.5->genslm==0.0.4a1) (3.23.0)\n",
      "Using cached h5py-3.7.0-cp39-cp39-macosx_11_0_arm64.whl (2.6 MB)\n",
      "Using cached lightning_transformers-0.2.1-py3-none-any.whl (76 kB)\n",
      "Using cached pydantic-1.10.2-cp39-cp39-macosx_11_0_arm64.whl (2.6 MB)\n",
      "Using cached pytorch_lightning-1.6.5-py3-none-any.whl (585 kB)\n",
      "Using cached protobuf-3.20.1-py2.py3-none-any.whl (162 kB)\n",
      "Using cached jinja2-3.1.6-py3-none-any.whl (134 kB)\n",
      "Using cached natsort-8.4.0-py3-none-any.whl (38 kB)\n",
      "Using cached pandas-2.3.2-cp39-cp39-macosx_11_0_arm64.whl (10.8 MB)\n",
      "Using cached wandb-0.21.1-py3-none-macosx_11_0_arm64.whl (21.2 MB)\n",
      "Using cached click-8.1.8-py3-none-any.whl (98 kB)\n",
      "Using cached gitpython-3.1.45-py3-none-any.whl (208 kB)\n",
      "Using cached MarkupSafe-3.0.2-cp39-cp39-macosx_11_0_arm64.whl (12 kB)\n",
      "Using cached pyDeprecate-0.3.2-py3-none-any.whl (10 kB)\n",
      "Using cached pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
      "Using cached sentry_sdk-2.35.1-py2.py3-none-any.whl (363 kB)\n",
      "Using cached tensorboard-2.20.0-py3-none-any.whl (5.5 MB)\n",
      "Using cached torch-2.8.0-cp39-none-macosx_11_0_arm64.whl (73.6 MB)\n",
      "Using cached tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
      "Using cached datasets-2.14.4-py3-none-any.whl (519 kB)\n",
      "Using cached eval_type_backport-0.2.2-py3-none-any.whl (5.8 kB)\n",
      "Using cached pillow-11.3.0-cp39-cp39-macosx_11_0_arm64.whl (4.7 MB)\n",
      "Using cached sentencepiece-0.2.1-cp39-cp39-macosx_11_0_arm64.whl (1.3 MB)\n",
      "Using cached torchmetrics-1.7.3-py3-none-any.whl (962 kB)\n",
      "Using cached absl_py-2.3.1-py3-none-any.whl (135 kB)\n",
      "Using cached aiohttp-3.12.15-cp39-cp39-macosx_11_0_arm64.whl (469 kB)\n",
      "Using cached dill-0.3.7-py3-none-any.whl (115 kB)\n",
      "Using cached gitdb-4.0.12-py3-none-any.whl (62 kB)\n",
      "Using cached grpcio-1.74.0-cp39-cp39-macosx_11_0_universal2.whl (11.0 MB)\n",
      "Using cached lightning_utilities-0.15.2-py3-none-any.whl (29 kB)\n",
      "Using cached markdown-3.8.2-py3-none-any.whl (106 kB)\n",
      "Using cached mecab_python3-1.0.10-cp39-cp39-macosx_11_0_arm64.whl (483 kB)\n",
      "Using cached nltk-3.9.1-py3-none-any.whl (1.5 MB)\n",
      "Using cached pyarrow-21.0.0-cp39-cp39-macosx_12_0_arm64.whl (31.2 MB)\n",
      "Using cached sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
      "Using cached tensorboard_data_server-0.7.2-py3-none-any.whl (2.4 kB)\n",
      "Using cached werkzeug-3.1.3-py3-none-any.whl (224 kB)\n",
      "Using cached multiprocess-0.70.15-py39-none-any.whl (133 kB)\n",
      "Using cached networkx-3.2.1-py3-none-any.whl (1.6 MB)\n",
      "Using cached xxhash-3.5.0-cp39-cp39-macosx_11_0_arm64.whl (30 kB)\n",
      "Using cached aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\n",
      "Using cached aiosignal-1.4.0-py3-none-any.whl (7.5 kB)\n",
      "Using cached async_timeout-5.0.1-py3-none-any.whl (6.2 kB)\n",
      "Using cached attrs-25.3.0-py3-none-any.whl (63 kB)\n",
      "Using cached frozenlist-1.7.0-cp39-cp39-macosx_11_0_arm64.whl (47 kB)\n",
      "Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "Using cached multidict-6.6.4-cp39-cp39-macosx_11_0_arm64.whl (44 kB)\n",
      "Using cached propcache-0.3.2-cp39-cp39-macosx_11_0_arm64.whl (43 kB)\n",
      "Using cached smmap-5.0.2-py3-none-any.whl (24 kB)\n",
      "Using cached yarl-1.20.1-cp39-cp39-macosx_11_0_arm64.whl (89 kB)\n",
      "Using cached joblib-1.5.1-py3-none-any.whl (307 kB)\n",
      "Building wheels for collected packages: genslm, transformers, tokenizers\n",
      "  Building wheel for genslm (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for genslm: filename=genslm-0.0.4a1-py3-none-any.whl size=65671 sha256=f35e1c99b1244b0aa46071fde486458e067cf1494db9e3b4c5a1217ff9029279\n",
      "  Stored in directory: /private/var/folders/kb/4rj6v4lj55b0h_wrblbl2pt80000gp/T/pip-ephem-wheel-cache-uz0qp0ae/wheels/4c/23/f8/4a6fab4deb9e25c7703792d36c2418dfde9475c8cc9bb5170d\n",
      "  Building wheel for transformers (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for transformers: filename=transformers-4.21.0.dev0-py3-none-any.whl size=4438181 sha256=a7d01b28e52f5ca13c791820f2c2dde2c669974f02370dce068027111bafa9c7\n",
      "  Stored in directory: /private/var/folders/kb/4rj6v4lj55b0h_wrblbl2pt80000gp/T/pip-ephem-wheel-cache-uz0qp0ae/wheels/42/c6/1b/72e2da1925b7200dfb4b82656122519da96e04b59bfbc8973a\n",
      "  Building wheel for tokenizers (pyproject.toml) ... \u001b[?25lerror\n",
      "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
      "  \n",
      "  \u001b[31m×\u001b[0m \u001b[32mBuilding wheel for tokenizers \u001b[0m\u001b[1;32m(\u001b[0m\u001b[32mpyproject.toml\u001b[0m\u001b[1;32m)\u001b[0m did not run successfully.\n",
      "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
      "  \u001b[31m╰─>\u001b[0m \u001b[31m[62 lines of output]\u001b[0m\n",
      "  \u001b[31m   \u001b[0m /private/var/folders/kb/4rj6v4lj55b0h_wrblbl2pt80000gp/T/pip-build-env-fhfzkb5j/overlay/lib/python3.9/site-packages/setuptools/dist.py:759: SetuptoolsDeprecationWarning: License classifiers are deprecated.\n",
      "  \u001b[31m   \u001b[0m !!\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         ********************************************************************************\n",
      "  \u001b[31m   \u001b[0m         Please consider removing the following classifiers in favor of a SPDX license expression:\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         License :: OSI Approved :: Apache Software License\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         See https://packaging.python.org/en/latest/guides/writing-pyproject-toml/#license for details.\n",
      "  \u001b[31m   \u001b[0m         ********************************************************************************\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m !!\n",
      "  \u001b[31m   \u001b[0m   self._finalize_license_expression()\n",
      "  \u001b[31m   \u001b[0m running bdist_wheel\n",
      "  \u001b[31m   \u001b[0m running build\n",
      "  \u001b[31m   \u001b[0m running build_py\n",
      "  \u001b[31m   \u001b[0m creating build/lib.macosx-11.0-arm64-cpython-39/tokenizers\n",
      "  \u001b[31m   \u001b[0m copying py_src/tokenizers/__init__.py -> build/lib.macosx-11.0-arm64-cpython-39/tokenizers\n",
      "  \u001b[31m   \u001b[0m creating build/lib.macosx-11.0-arm64-cpython-39/tokenizers/models\n",
      "  \u001b[31m   \u001b[0m copying py_src/tokenizers/models/__init__.py -> build/lib.macosx-11.0-arm64-cpython-39/tokenizers/models\n",
      "  \u001b[31m   \u001b[0m creating build/lib.macosx-11.0-arm64-cpython-39/tokenizers/decoders\n",
      "  \u001b[31m   \u001b[0m copying py_src/tokenizers/decoders/__init__.py -> build/lib.macosx-11.0-arm64-cpython-39/tokenizers/decoders\n",
      "  \u001b[31m   \u001b[0m creating build/lib.macosx-11.0-arm64-cpython-39/tokenizers/normalizers\n",
      "  \u001b[31m   \u001b[0m copying py_src/tokenizers/normalizers/__init__.py -> build/lib.macosx-11.0-arm64-cpython-39/tokenizers/normalizers\n",
      "  \u001b[31m   \u001b[0m creating build/lib.macosx-11.0-arm64-cpython-39/tokenizers/pre_tokenizers\n",
      "  \u001b[31m   \u001b[0m copying py_src/tokenizers/pre_tokenizers/__init__.py -> build/lib.macosx-11.0-arm64-cpython-39/tokenizers/pre_tokenizers\n",
      "  \u001b[31m   \u001b[0m creating build/lib.macosx-11.0-arm64-cpython-39/tokenizers/processors\n",
      "  \u001b[31m   \u001b[0m copying py_src/tokenizers/processors/__init__.py -> build/lib.macosx-11.0-arm64-cpython-39/tokenizers/processors\n",
      "  \u001b[31m   \u001b[0m creating build/lib.macosx-11.0-arm64-cpython-39/tokenizers/trainers\n",
      "  \u001b[31m   \u001b[0m copying py_src/tokenizers/trainers/__init__.py -> build/lib.macosx-11.0-arm64-cpython-39/tokenizers/trainers\n",
      "  \u001b[31m   \u001b[0m creating build/lib.macosx-11.0-arm64-cpython-39/tokenizers/implementations\n",
      "  \u001b[31m   \u001b[0m copying py_src/tokenizers/implementations/byte_level_bpe.py -> build/lib.macosx-11.0-arm64-cpython-39/tokenizers/implementations\n",
      "  \u001b[31m   \u001b[0m copying py_src/tokenizers/implementations/sentencepiece_unigram.py -> build/lib.macosx-11.0-arm64-cpython-39/tokenizers/implementations\n",
      "  \u001b[31m   \u001b[0m copying py_src/tokenizers/implementations/sentencepiece_bpe.py -> build/lib.macosx-11.0-arm64-cpython-39/tokenizers/implementations\n",
      "  \u001b[31m   \u001b[0m copying py_src/tokenizers/implementations/base_tokenizer.py -> build/lib.macosx-11.0-arm64-cpython-39/tokenizers/implementations\n",
      "  \u001b[31m   \u001b[0m copying py_src/tokenizers/implementations/__init__.py -> build/lib.macosx-11.0-arm64-cpython-39/tokenizers/implementations\n",
      "  \u001b[31m   \u001b[0m copying py_src/tokenizers/implementations/char_level_bpe.py -> build/lib.macosx-11.0-arm64-cpython-39/tokenizers/implementations\n",
      "  \u001b[31m   \u001b[0m copying py_src/tokenizers/implementations/bert_wordpiece.py -> build/lib.macosx-11.0-arm64-cpython-39/tokenizers/implementations\n",
      "  \u001b[31m   \u001b[0m creating build/lib.macosx-11.0-arm64-cpython-39/tokenizers/tools\n",
      "  \u001b[31m   \u001b[0m copying py_src/tokenizers/tools/__init__.py -> build/lib.macosx-11.0-arm64-cpython-39/tokenizers/tools\n",
      "  \u001b[31m   \u001b[0m copying py_src/tokenizers/tools/visualizer.py -> build/lib.macosx-11.0-arm64-cpython-39/tokenizers/tools\n",
      "  \u001b[31m   \u001b[0m copying py_src/tokenizers/__init__.pyi -> build/lib.macosx-11.0-arm64-cpython-39/tokenizers\n",
      "  \u001b[31m   \u001b[0m copying py_src/tokenizers/models/__init__.pyi -> build/lib.macosx-11.0-arm64-cpython-39/tokenizers/models\n",
      "  \u001b[31m   \u001b[0m copying py_src/tokenizers/decoders/__init__.pyi -> build/lib.macosx-11.0-arm64-cpython-39/tokenizers/decoders\n",
      "  \u001b[31m   \u001b[0m copying py_src/tokenizers/normalizers/__init__.pyi -> build/lib.macosx-11.0-arm64-cpython-39/tokenizers/normalizers\n",
      "  \u001b[31m   \u001b[0m copying py_src/tokenizers/pre_tokenizers/__init__.pyi -> build/lib.macosx-11.0-arm64-cpython-39/tokenizers/pre_tokenizers\n",
      "  \u001b[31m   \u001b[0m copying py_src/tokenizers/processors/__init__.pyi -> build/lib.macosx-11.0-arm64-cpython-39/tokenizers/processors\n",
      "  \u001b[31m   \u001b[0m copying py_src/tokenizers/trainers/__init__.pyi -> build/lib.macosx-11.0-arm64-cpython-39/tokenizers/trainers\n",
      "  \u001b[31m   \u001b[0m copying py_src/tokenizers/tools/visualizer-styles.css -> build/lib.macosx-11.0-arm64-cpython-39/tokenizers/tools\n",
      "  \u001b[31m   \u001b[0m running build_ext\n",
      "  \u001b[31m   \u001b[0m running build_rust\n",
      "  \u001b[31m   \u001b[0m error: can't find Rust compiler\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m If you are using an outdated pip version, it is possible a prebuilt wheel is available for this package but pip is not able to install from it. Installing from the wheel would avoid the need for a Rust compiler.\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m To update pip, run:\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m     pip install --upgrade pip\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m and then retry package installation.\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m If you did intend to build this package from source, try installing a Rust compiler from your system package manager and ensure it is on the PATH during installation. Alternatively, rustup (available at https://rustup.rs) is the recommended way to download and update the Rust compiler toolchain.\n",
      "  \u001b[31m   \u001b[0m \u001b[31m[end of output]\u001b[0m\n",
      "  \n",
      "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "\u001b[?25h\u001b[31m  ERROR: Failed building wheel for tokenizers\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully built genslm transformers\n",
      "Failed to build tokenizers\n",
      "\u001b[31mERROR: Could not build wheels for tokenizers, which is required to install pyproject.toml-based projects\u001b[0m\u001b[31m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# NOTE: You may need to run this twice due to a pip dependency conflict\n",
    "# !pip install git+https://github.com/ramanathanlab/genslm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lrW0XAytDo_h",
    "outputId": "cee6457d-a564-4f16-9b75-7ebf4f272d64"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/gdrive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "\n",
    "drive.mount(\"/content/gdrive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nEjqvA64D5MX",
    "outputId": "ad60b947-9263-4b16-d67c-6d2ce0eba250"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patric_25m_epoch01-val_loss_0.57_bias_removed.pt\n"
     ]
    }
   ],
   "source": [
    "!ls ~/projects/exascale/genslm/models/25M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dI0g0tXqDDpJ",
    "outputId": "ee41c4df-734c-4c74-cbf9-df2d583e1f6e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/jdtibochab/.local/share/mamba/envs/genslm-py37/lib/python3.7/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Tokenizing...: 100%|██████████| 2/2 [00:00<00:00, 535.19it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2, 512)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "from genslm import GenSLM, SequenceDataset\n",
    "\n",
    "# Load model\n",
    "# model = GenSLM(\"genslm_25M_patric\", model_cache_dir=\"/content/gdrive/MyDrive\")\n",
    "model = GenSLM(\"genslm_25M_patric\", model_cache_dir=\"/users/jdtibochab/projects/exascale/genslm/models/25M\")\n",
    "\n",
    "model.eval()\n",
    "\n",
    "# Select GPU device if it is available, else use CPU\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model.to(device)\n",
    "\n",
    "# Input data is a list of gene sequences\n",
    "sequences = [\n",
    "    \"ATGAAAGTAACCGTTGTTGGAGCAGGTGCAGTTGGTGCAAGTTGCGCAGAATATATTGCA\",\n",
    "    \"ATTAAAGATTTCGCATCTGAAGTTGTTTTGTTAGACATTAAAGAAGGTTATGCCGAAGGT\",\n",
    "]\n",
    "\n",
    "dataset = SequenceDataset(sequences, model.seq_length, model.tokenizer)\n",
    "dataloader = DataLoader(dataset)\n",
    "\n",
    "# Compute averaged-embeddings for each input sequence\n",
    "embeddings = []\n",
    "with torch.no_grad():\n",
    "    for batch in dataloader:\n",
    "        outputs = model(\n",
    "            batch[\"input_ids\"].to(device),\n",
    "            batch[\"attention_mask\"].to(device),\n",
    "            output_hidden_states=True,\n",
    "        )\n",
    "        # outputs.hidden_states shape: (layers, batch_size, sequence_length, hidden_size)\n",
    "        # Use the embeddings of the last layer\n",
    "        emb = outputs.hidden_states[-1].detach().cpu().numpy()\n",
    "        # Compute average over sequence length\n",
    "        emb = np.mean(emb, axis=1)\n",
    "        embeddings.append(emb)\n",
    "\n",
    "# Concatenate embeddings into an array of shape (num_sequences, hidden_size)\n",
    "embeddings = np.concatenate(embeddings)\n",
    "embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Tt8zLQyNDDpL"
   },
   "outputs": [],
   "source": [
    "# NOTE: This is not the best performance you can get. For a scalable implementation,\n",
    "# refer to genslm.cmdline.run_inference for an example of how to utilize multiple\n",
    "# GPUs for parallel inference."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "genslm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
